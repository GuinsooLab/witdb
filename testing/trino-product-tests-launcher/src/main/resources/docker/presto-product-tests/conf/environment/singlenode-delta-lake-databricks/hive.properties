connector.name=hive
hive.metastore=glue
hive.metastore.glue.region=${ENV:AWS_REGION}
# We need to give access to bucket owner (the AWS account integrated with Databricks), otherwise files won't be readable from Databricks
hive.s3.upload-acl-type=BUCKET_OWNER_FULL_CONTROL
hive.allow-drop-table=true
hive.non-managed-table-writes-enabled=true
# Required by some product tests
hive.hive-views.enabled=true
hive.allow-comment-table=true
hive.allow-comment-column=true
hive.allow-rename-table=true
hive.delta-lake-catalog-name=delta
